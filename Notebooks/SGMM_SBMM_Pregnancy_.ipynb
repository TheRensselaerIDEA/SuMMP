{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../sgmm')\n",
    "sys.path.append('../metrics')\n",
    "sys.path.append('../Misc')\n",
    "sys.path.append('../visual')\n",
    "sys.path.append('../otherModels')\n",
    "sys.path.append('../LogOdds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from supervisedGmm import SupervisedGMM\n",
    "from metricsFunctions import calc_metrics, CalculateSoftLogReg, optimalTau,metrics_cluster,sgmmResults\n",
    "from mlModels import logisticRegressionCv2, neural_nets, randomforests,\\\n",
    "kmeansLogRegr, xboost, gradboost\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from supervisedBmm import SupervisedBMM\n",
    "from utility import entropy,asymm_entropy,purity\n",
    "from ftest_logodds import ftest_uncorr\n",
    "from ftest_logodds import restest\n",
    "#from clustmap import plotclustmap\n",
    "from clustmap_newborn import plotclustmap\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100679 244\n"
     ]
    }
   ],
   "source": [
    "sparcs = pd.read_csv(\"~/data/CDPHP/xiao/SPARCS_Subsets/Obsolete/sparcs25%Preg_DeHos_Outflow_Region.csv\") \n",
    "\n",
    "d_preg_tr, d_preg_te = train_test_split(sparcs, test_size=0.2, random_state = 1512)\n",
    "\n",
    "print(d_preg_tr.shape[0], d_preg_tr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125849\n"
     ]
    }
   ],
   "source": [
    "print(sparcs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric matrix columns\n",
    "columns = ['cluster', 'size', 'high_cost%','low_cost%', \n",
    "                       'TP', 'TN', 'FP', 'FN', \n",
    "                       'FPR', 'specificity', 'sensitivity', 'precision',\n",
    "                       'accuracy', 'balanced accuracy', 'f1', 'auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature list\n",
    "features = list(sparcs.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the data\n",
    "Xtrain, Xtest = d_preg_tr.iloc[:,0:-1].values, d_preg_te.iloc[:,0:-1].values\n",
    "ytrain, ytest = d_preg_tr.iloc[:,-1].values.astype(int), d_preg_te.iloc[:,-1].values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonclustering Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a Bernoulli Naive Bayes\n",
    "bnb = BernoulliNB(alpha= 1,class_prior=[0.75,0.25])\n",
    "bnb.fit(Xtrain, ytrain)\n",
    "probTrainNB,probTestNB = bnb.predict_proba(Xtrain)[:,1], bnb.predict_proba(Xtest)[:,1]\n",
    "tau = optimalTau(probTrainNB, ytrain)\n",
    "metTest,_ = calc_metrics(custom_prob = probTestNB.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrainNB.copy(), tau = tau, y = ytrain)\n",
    "metTestNB = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainNB = pd.DataFrame( [metTrain], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING L1 LOGISTIC REGRESSION\n",
    "Cs = [1,10,100,1000]\n",
    "pL1, probTestL1, probTrainL1 = logisticRegressionCv2( Xtrain = Xtrain,\n",
    "                                                  ytrain = ytrain,\n",
    "                                                  Xtest = Xtest,\n",
    "                                                  ytest = ytest, Cs = Cs )\n",
    "tau = optimalTau(probTrainL1, ytrain)\n",
    "\n",
    "metTest,_ = calc_metrics(custom_prob = probTestL1.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrainL1.copy(), tau = tau, y = ytrain)\n",
    "metTestL1 = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainL1 = pd.DataFrame( [metTrain], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Neural Nets\n",
    "pNN, probTestNN, probTrainNN = neural_nets( Xtrain = Xtrain,\n",
    "                                                  ytrain = ytrain,\n",
    "                                                  Xtest = Xtest,\n",
    "                                                  ytest = ytest,\n",
    "                                                  h_l_s = (4 ,4, 2))\n",
    "tau = optimalTau(probTrainNN, ytrain)\n",
    "\n",
    "metTest,_ = calc_metrics(custom_prob = probTestNN.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrainNN.copy(), tau = tau, y = ytrain)\n",
    "metTestNN = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainNN = pd.DataFrame( [metTrain], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FORESTS\n",
    "params, probTest, probTrain = randomforests(Xtrain = Xtrain, ytrain = ytrain,\n",
    "                                            Xtest = Xtest, ytest = ytest)\n",
    "\n",
    "tau = optimalTau(probTrain, ytrain)\n",
    "metTest,_ = calc_metrics(custom_prob = probTest.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrain.copy(), tau = tau, y = ytrain)\n",
    "\n",
    "#PANDA MATRICES\n",
    "metTestRF = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainRF = pd.DataFrame( [metTrain], columns = columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ada boost\n",
    "params, probTest, probTrain = xboost(Xtrain = Xtrain, ytrain = ytrain,\n",
    "                                            Xtest = Xtest, ytest = ytest)\n",
    "\n",
    "tau = optimalTau(probTrain, ytrain)\n",
    "metTest,_ = calc_metrics(custom_prob = probTest.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrain.copy(), tau = tau, y = ytrain)\n",
    "\n",
    "#PANDA MATRICES\n",
    "metTestXB = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainXB = pd.DataFrame( [metTrain], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grad boost\n",
    "params, probTest, probTrain = gradboost(Xtrain = Xtrain, ytrain = ytrain,\n",
    "                                            Xtest = Xtest, ytest = ytest)\n",
    "\n",
    "tau = optimalTau(probTrain, ytrain)\n",
    "metTest,_ = calc_metrics(custom_prob = probTest.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrain.copy(), tau = tau, y = ytrain)\n",
    "\n",
    "#PANDA MATRICES\n",
    "metTestGB = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainGB = pd.DataFrame( [metTrain], columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential clustering + classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kmeans + LG\n",
    "np.random.seed( seed = 0 )\n",
    "\n",
    "n_clusters = 8\n",
    "\n",
    "Cs = [1,10,100,1000]\n",
    "kmeansParams = kmeansLogRegr(Xtrain = Xtrain, ytrain = ytrain, \n",
    "                             Xtest = Xtest, ytest = ytest, Cs = Cs, n_clusters = n_clusters)\n",
    "\n",
    "modelsKM = kmeansParams['models']\n",
    "labTrKM, labTestKM  = kmeansParams['labelsTrain'], kmeansParams['labelsTest']\n",
    "\n",
    "\n",
    "# KMS class accuracy\n",
    "metTrainKMc, metTestKMc = metrics_cluster(models = modelsKM, ytrain = ytrain,\n",
    "                                        ytest = ytest, testlabels = labTestKM,\n",
    "                                        trainlabels = labTrKM,\n",
    "                                        Xtrain = Xtrain, Xtest = Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMS LG overall accuaracy\n",
    "probTr= np.array([])\n",
    "for i in range(len(kmeansParams['probTrain'])):\n",
    "    probTr = np.append(probTr,kmeansParams['probTrain'][i])\n",
    "yTr = np. array([])\n",
    "for i in range(n_clusters):\n",
    "    yTr = np.append(yTr,ytrain[labTrKM==i])\n",
    "\n",
    "probTe= np.array([])\n",
    "for i in range(len(kmeansParams['probTest'])):\n",
    "    probTe = np.append(probTe,kmeansParams['probTest'][i])\n",
    "yTe = np. array([])\n",
    "for i in range(n_clusters):\n",
    "    yTe = np.append(yTe,ytest[labTestKM==i])\n",
    "\n",
    "tau = optimalTau(probTr, yTr)\n",
    "\n",
    "metTrain ,__= calc_metrics(y = yTr, tau = tau, custom_prob = probTr)\n",
    "metTest ,__= calc_metrics( y = yTe, tau = tau, custom_prob = probTe)\n",
    "metTrainKMS = pd.DataFrame( [metTrain], columns = columns)\n",
    "metTestKMS = pd.DataFrame( [metTest], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM iteration: 0, error: 0.20276032428298818\n",
      "GMM iteration: 1, error: 0.05967110690273707\n",
      "GMM iteration: 2, error: 0.012208029408162877\n",
      "GMM iteration: 3, error: 0.003032847519465272\n",
      "GMM iteration: 4, error: 0.0006929119113580264\n"
     ]
    }
   ],
   "source": [
    "# train SGMM model with Log Regression\n",
    "np.random.seed( seed = 3957 )\n",
    "\n",
    "max_iter = 30\n",
    "max_iter2 = 30\n",
    "n_clusters = 8\n",
    "\n",
    "model = SupervisedGMM(max_iter=max_iter, max_iter2 = max_iter2, n_clusters = n_clusters, verbose = 0)\n",
    "model = model.fit(Xtrain = Xtrain, ytrain = ytrain)\n",
    "\n",
    "# Retrieve memberships and labels\n",
    "mTrainSGMM = model.mTrain\n",
    "logisRegreSGMM = model.LogRegr\n",
    "fitP = model.fitParams\n",
    "labTrainSGMM  = fitP['labTrain']\n",
    "mTestSGMM = model.predict_GMMS(Xtest)\n",
    "labTestSGMM = np.argmax( mTestSGMM, axis = 1 )\n",
    "\n",
    "# Summary of overall accuracy \n",
    "probTest, probTrain = model.predict_prob_int( Xtest = Xtest, Xtrain = Xtrain )\n",
    "tau = optimalTau(probTrain, ytrain)\n",
    "metTest,_ = calc_metrics(custom_prob = probTest.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrain.copy(), tau = tau, y = ytrain)\n",
    "metTestSGMM = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainSGMM = pd.DataFrame( [metTrain], columns = columns)\n",
    "\n",
    "# Cluster summary\n",
    "metTrainSGc, metTestSGc = metrics_cluster(models = logisRegreSGMM, ytrain = ytrain,\n",
    "                                        ytest = ytest, testlabels = labTestSGMM,\n",
    "                                        trainlabels = labTrainSGMM,\n",
    "                                        Xtrain = Xtrain, Xtest = Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMM iteration: 0, error: 0.05956246079127828\n",
      "BMM iteration: 1, error: 0.012337373483863457\n",
      "BMM iteration: 2, error: 0.01266240618360524\n",
      "BMM iteration: 3, error: 0.04061405027848652\n",
      "BMM iteration: 4, error: 0.06480344942806185\n",
      "BMM iteration: 5, error: 0.052282351250163464\n",
      "BMM iteration: 6, error: 0.05402750929868193\n",
      "BMM iteration: 7, error: 0.049680640240205895\n",
      "BMM iteration: 8, error: 0.034007107757107045\n",
      "BMM iteration: 9, error: 0.02152434792977026\n",
      "BMM iteration: 10, error: 0.01639227210332293\n",
      "BMM iteration: 11, error: 0.014915466318168277\n",
      "BMM iteration: 12, error: 0.013945724166356397\n",
      "BMM iteration: 13, error: 0.012211535194671557\n",
      "BMM iteration: 14, error: 0.010027819705238875\n",
      "BMM iteration: 15, error: 0.00770808272376263\n",
      "BMM iteration: 16, error: 0.0055139656366097675\n",
      "BMM iteration: 17, error: 0.003886611842106428\n",
      "BMM iteration: 18, error: 0.0029741389947466968\n",
      "BMM iteration: 19, error: 0.0022205666874090335\n",
      "BMM iteration: 20, error: 0.0018110393985449494\n",
      "BMM iteration: 21, error: 0.0016908088204132948\n",
      "BMM iteration: 22, error: 0.0017953594983671835\n",
      "BMM iteration: 23, error: 0.0020233507577237055\n",
      "BMM iteration: 24, error: 0.002339610595518901\n",
      "BMM iteration: 25, error: 0.002664080211627338\n",
      "BMM iteration: 26, error: 0.003029443156489073\n",
      "BMM iteration: 27, error: 0.0033376919894354275\n",
      "BMM iteration: 28, error: 0.003873922948071842\n",
      "BMM iteration: 29, error: 0.0048285884932492435\n"
     ]
    }
   ],
   "source": [
    "# train SBMM model with Log Regression\n",
    "np.random.seed( seed = 7332  )\n",
    "\n",
    "max_iter = 30\n",
    "max_iter2 = 30\n",
    "n_clusters = 8\n",
    "\n",
    "modelB = SupervisedBMM( max_iter =max_iter, n_clusters = n_clusters, max_iter2 = max_iter2,verbose =0)\n",
    "modelB = modelB.fitB( Xtrain = Xtrain, Xtest = Xtest, ytrain = ytrain)\n",
    "\n",
    "mTrainSBMM = modelB.mTrain\n",
    "logisRegreB = modelB.LogRegr\n",
    "fitPB = modelB.fitParams\n",
    "labTrainSBMM  = fitPB['labTrain']\n",
    "mTestSBMM = modelB.predict_BMMS(Xtest)\n",
    "labTestSBMM = np.argmax( mTestSBMM, axis = 1 )\n",
    "\n",
    "probTestB, probTrainB = modelB.predict_prob_int_B( Xtest = Xtest, Xtrain = Xtrain )\n",
    "tauB = optimalTau(probTrainB, ytrain)\n",
    "metTestB,_ = calc_metrics(custom_prob = probTestB.copy(), tau = tauB, y = ytest)\n",
    "metTrainB ,_= calc_metrics(custom_prob = probTrainB.copy(), tau = tauB, y = ytrain)\n",
    "metTestSBMM = pd.DataFrame( [metTestB], columns = columns)\n",
    "metTrainSBMM = pd.DataFrame( [metTrainB], columns = columns)\n",
    "\n",
    "metTrainSBc, metTestSBc = metrics_cluster(models = logisRegreB, ytrain = ytrain,\n",
    "                                        ytest = ytest, testlabels = labTestSBMM,\n",
    "                                        trainlabels = labTrainSBMM,\n",
    "                                        Xtrain = Xtrain, Xtest = Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall predition accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison acucuracy with other methods\n",
    "trainmet = pd.concat([metTrainNB, metTrainL1,metTrainNN,metTrainRF,metTrainXB,metTrainGB, metTrainKMS,metTrainSGMM,metTrainSBMM],ignore_index=True)\n",
    "testmet = pd.concat([metTestNB, metTestL1,metTestNN,metTestRF,metTestXB,metTestGB, metTestKMS,metTestSGMM,metTestSBMM],ignore_index=True)\n",
    "method = ['Naive Bayes','L1 Log Reg','Neural Network','Random Forest','AdaBoost','GradBoost','KMS + Log Reg', 'SGMM w/ Log Reg', 'SBMM w/ Log Reg']\n",
    "trainmet.insert(8,'method',method)\n",
    "testmet.insert(8,'method',method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall prediction accuracy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>FPR</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1 Log Reg</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradBoost</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KMS + Log Reg</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGMM w/ Log Reg</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SBMM w/ Log Reg</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            method   FPR  specificity  sensitivity  precision  accuracy  \\\n",
       "0      Naive Bayes  0.25         0.75         0.68       0.48      0.73   \n",
       "1       L1 Log Reg  0.25         0.75         0.71       0.49      0.74   \n",
       "2   Neural Network  0.18         0.82         0.71       0.58      0.80   \n",
       "3    Random Forest  0.13         0.87         0.65       0.64      0.82   \n",
       "4         AdaBoost  0.27         0.73         0.71       0.48      0.73   \n",
       "5        GradBoost  0.26         0.74         0.75       0.50      0.75   \n",
       "6    KMS + Log Reg  0.18         0.82         0.69       0.57      0.79   \n",
       "7  SGMM w/ Log Reg  0.26         0.74         0.72       0.49      0.74   \n",
       "8  SBMM w/ Log Reg  0.16         0.84         0.68       0.59      0.80   \n",
       "\n",
       "   balanced accuracy    f1   auc  \n",
       "0               0.71  0.56  0.80  \n",
       "1               0.73  0.58  0.82  \n",
       "2               0.77  0.64  0.85  \n",
       "3               0.76  0.64  0.86  \n",
       "4               0.72  0.57  0.81  \n",
       "5               0.75  0.60  0.83  \n",
       "6               0.76  0.62  0.85  \n",
       "7               0.73  0.58  0.82  \n",
       "8               0.76  0.63  0.85  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( 'Overall prediction accuracy')\n",
    "testmet.iloc[:,8:].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cadre wise prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans + LG\n",
      "     size  high_cost%    f1   auc\n",
      "0  2877.0        0.13  0.57  0.90\n",
      "1  3047.0        0.16  0.55  0.85\n",
      "2  3175.0        0.22  0.51  0.76\n",
      "3  2160.0        0.23  0.60  0.85\n",
      "4  4991.0        0.24  0.56  0.79\n",
      "5  3222.0        0.31  0.63  0.82\n",
      "6  3221.0        0.32  0.65  0.83\n",
      "7  2477.0        0.43  0.80  0.90\n",
      "SGMM w/ LG\n",
      "      size  high_cost%    f1   auc\n",
      "0    132.0        0.06  0.63  0.95\n",
      "1    228.0        0.06  0.53  0.92\n",
      "2    318.0        0.12  0.49  0.91\n",
      "3    653.0        0.17  0.58  0.87\n",
      "4    121.0        0.18  0.49  0.86\n",
      "5    106.0        0.21  0.37  0.83\n",
      "6  23504.0        0.26  0.58  0.81\n",
      "7    108.0        0.31  0.66  0.84\n",
      "SBMM w/ LG\n",
      "     size  high_cost%    f1   auc\n",
      "0  3449.0        0.07  0.53  0.91\n",
      "1  2486.0        0.09  0.61  0.92\n",
      "2  6521.0        0.20  0.49  0.76\n",
      "3  3343.0        0.24  0.55  0.79\n",
      "4  1573.0        0.31  0.62  0.83\n",
      "5  1012.0        0.33  0.69  0.87\n",
      "6  2421.0        0.38  0.70  0.83\n",
      "7  4365.0        0.48  0.71  0.76\n"
     ]
    }
   ],
   "source": [
    "print('Kmeans + LG')\n",
    "print(metTestKMc.round(2).sort_values(by ='high_cost%').reset_index().iloc[:,np.r_[2:4,-2,-1]])\n",
    "print('SGMM w/ LG')\n",
    "print(metTestSGc.round(2).sort_values(by ='high_cost%').reset_index().iloc[:,np.r_[2:4,-2,-1]]) #.iloc [[1,0,2,3,4],:]) \n",
    "print('SBMM w/ LG')\n",
    "print(metTestSBc.round(2).sort_values(by ='high_cost%').reset_index().iloc[:,np.r_[2:4,-2,-1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (health3)",
   "language": "python",
   "name": "health3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
