{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../sgmm')\n",
    "sys.path.append('../metrics')\n",
    "sys.path.append('../Misc')\n",
    "sys.path.append('../visual')\n",
    "sys.path.append('../otherModels')\n",
    "sys.path.append('../LogOdds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from supervisedGmm import SupervisedGMM\n",
    "from metricsFunctions import calc_metrics, CalculateSoftLogReg, optimalTau,metrics_cluster,sgmmResults\n",
    "from mlModels import logisticRegressionCv2, neural_nets, randomforests,\\\n",
    "kmeansLogRegr, xboost, gradboost,kmeansBNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from supervisedBmm import SupervisedBMM\n",
    "from utility import entropy,asymm_entropy,purity\n",
    "from ftest_logodds import ftest_uncorr\n",
    "from ftest_logodds import restest\n",
    "#from clustmap import plotclustmap\n",
    "#from clustmap_newborn import plotclustmap\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39888 301\n"
     ]
    }
   ],
   "source": [
    "sparcs = pd.read_csv(\"~/data/CDPHP/xiao/SPARCS_Subsets/Obsolete/sparcs25%Circ_DeHos_Outflow_Region.csv\") \n",
    "\n",
    "d_circ_tr, d_circ_te = train_test_split(sparcs, test_size=0.2, random_state = 1512)\n",
    "\n",
    "print(d_circ_tr.shape[0], d_circ_tr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric matrix columns\n",
    "columns = ['cluster', 'size', 'high_cost%','low_cost%', \n",
    "                       'TP', 'TN', 'FP', 'FN', \n",
    "                       'FPR', 'specificity', 'sensitivity', 'precision',\n",
    "                       'accuracy', 'balanced accuracy', 'f1', 'auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature list\n",
    "features = list(sparcs.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the data\n",
    "Xtrain, Xtest = d_circ_tr.iloc[:,0:-1].values, d_circ_te.iloc[:,0:-1].values\n",
    "ytrain, ytest = d_circ_tr.iloc[:,-1].values.astype(int), d_circ_te.iloc[:,-1].values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonclustering Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a Bernoulli Naive Bayes\n",
    "bnb = BernoulliNB(alpha= 1,class_prior=[0.75,0.25])\n",
    "bnb.fit(Xtrain, ytrain)\n",
    "probTrainNB,probTestNB = bnb.predict_proba(Xtrain)[:,1], bnb.predict_proba(Xtest)[:,1]\n",
    "tau = optimalTau(probTrainNB, ytrain)\n",
    "metTest,_ = calc_metrics(custom_prob = probTestNB.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrainNB.copy(), tau = tau, y = ytrain)\n",
    "metTestNB = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainNB = pd.DataFrame( [metTrain], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING L1 LOGISTIC REGRESSION\n",
    "Cs = [1,10,100,1000]\n",
    "pL1, probTestL1, probTrainL1 = logisticRegressionCv2( Xtrain = Xtrain,\n",
    "                                                  ytrain = ytrain,\n",
    "                                                  Xtest = Xtest,\n",
    "                                                  ytest = ytest, Cs = Cs )\n",
    "tau = optimalTau(probTrainL1, ytrain)\n",
    "\n",
    "metTest,_ = calc_metrics(custom_prob = probTestL1.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrainL1.copy(), tau = tau, y = ytrain)\n",
    "metTestL1 = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainL1 = pd.DataFrame( [metTrain], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Neural Nets\n",
    "pNN, probTestNN, probTrainNN = neural_nets( Xtrain = Xtrain,\n",
    "                                                  ytrain = ytrain,\n",
    "                                                  Xtest = Xtest,\n",
    "                                                  ytest = ytest,\n",
    "                                                  h_l_s = (4 ,4, 2))\n",
    "tau = optimalTau(probTrainNN, ytrain)\n",
    "\n",
    "metTest,_ = calc_metrics(custom_prob = probTestNN.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrainNN.copy(), tau = tau, y = ytrain)\n",
    "metTestNN = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainNN = pd.DataFrame( [metTrain], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FORESTS\n",
    "params, probTest, probTrain = randomforests(Xtrain = Xtrain, ytrain = ytrain,\n",
    "                                            Xtest = Xtest, ytest = ytest)\n",
    "\n",
    "tau = optimalTau(probTrain, ytrain)\n",
    "metTest,_ = calc_metrics(custom_prob = probTest.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrain.copy(), tau = tau, y = ytrain)\n",
    "\n",
    "#PANDA MATRICES\n",
    "metTestRF = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainRF = pd.DataFrame( [metTrain], columns = columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ada boost\n",
    "params, probTest, probTrain = xboost(Xtrain = Xtrain, ytrain = ytrain,\n",
    "                                            Xtest = Xtest, ytest = ytest)\n",
    "\n",
    "tau = optimalTau(probTrain, ytrain)\n",
    "metTest,_ = calc_metrics(custom_prob = probTest.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrain.copy(), tau = tau, y = ytrain)\n",
    "\n",
    "#PANDA MATRICES\n",
    "metTestXB = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainXB = pd.DataFrame( [metTrain], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grad boost\n",
    "params, probTest, probTrain = gradboost(Xtrain = Xtrain, ytrain = ytrain,\n",
    "                                            Xtest = Xtest, ytest = ytest)\n",
    "\n",
    "tau = optimalTau(probTrain, ytrain)\n",
    "metTest,_ = calc_metrics(custom_prob = probTest.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrain.copy(), tau = tau, y = ytrain)\n",
    "\n",
    "#PANDA MATRICES\n",
    "metTestGB = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainGB = pd.DataFrame( [metTrain], columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential clustering + classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kmeans + LG\n",
    "\n",
    "np.random.seed( seed = 0 )\n",
    "\n",
    "n_clusters = 7\n",
    "\n",
    "Cs = [1,10,100,1000]\n",
    "kmeansParams = kmeansLogRegr(Xtrain = Xtrain, ytrain = ytrain, \n",
    "                             Xtest = Xtest, ytest = ytest, Cs = Cs, n_clusters = n_clusters)\n",
    "\n",
    "modelsKM = kmeansParams['models']\n",
    "labTrKM, labTestKM  = kmeansParams['labelsTrain'], kmeansParams['labelsTest']\n",
    "\n",
    "\n",
    "# KMS class accuracy\n",
    "metTrainKMc, metTestKMc = metrics_cluster(models = modelsKM, ytrain = ytrain,\n",
    "                                        ytest = ytest, testlabels = labTestKM,\n",
    "                                        trainlabels = labTrKM,\n",
    "                                        Xtrain = Xtrain, Xtest = Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMS LG overall accuaracy\n",
    "probTr= np.array([])\n",
    "for i in range(len(kmeansParams['probTrain'])):\n",
    "    probTr = np.append(probTr,kmeansParams['probTrain'][i])\n",
    "yTr = np. array([])\n",
    "for i in range(n_clusters):\n",
    "    yTr = np.append(yTr,ytrain[labTrKM==i])\n",
    "\n",
    "probTe= np.array([])\n",
    "for i in range(len(kmeansParams['probTest'])):\n",
    "    probTe = np.append(probTe,kmeansParams['probTest'][i])\n",
    "yTe = np. array([])\n",
    "for i in range(n_clusters):\n",
    "    yTe = np.append(yTe,ytest[labTestKM==i])\n",
    "\n",
    "tau = optimalTau(probTr, yTr)\n",
    "\n",
    "metTrain ,__= calc_metrics(y = yTr, tau = tau, custom_prob = probTr)\n",
    "metTest ,__= calc_metrics( y = yTe, tau = tau, custom_prob = probTe)\n",
    "metTrainKMS = pd.DataFrame( [metTrain], columns = columns)\n",
    "metTestKMS = pd.DataFrame( [metTest], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM iteration: 0, error: 0.19600469100396917\n",
      "GMM iteration: 1, error: 0.10580530749126546\n",
      "GMM iteration: 2, error: 0.02414035191018011\n",
      "GMM iteration: 3, error: 0.0053016022607052776\n",
      "GMM iteration: 4, error: 0.0012897451797265664\n",
      "GMM iteration: 5, error: 0.0003292113293513271\n"
     ]
    }
   ],
   "source": [
    "# train SGMM model with Log Regression\n",
    "np.random.seed( seed = 94469 )\n",
    "\n",
    "max_iter = 30\n",
    "max_iter2 = 30\n",
    "n_clusters = 7\n",
    "\n",
    "model = SupervisedGMM( max_iter=max_iter, max_iter2 = max_iter2, n_clusters = n_clusters, verbose = 0)\n",
    "model = model.fit(Xtrain = Xtrain, ytrain = ytrain)\n",
    "\n",
    "# Retrieve memberships and labels\n",
    "mTrainSGMM = model.mTrain\n",
    "logisRegreSGMM = model.LogRegr\n",
    "fitP = model.fitParams\n",
    "labTrainSGMM  = fitP['labTrain']\n",
    "mTestSGMM = model.predict_GMMS(Xtest)\n",
    "labTestSGMM = np.argmax( mTestSGMM, axis = 1 )\n",
    "\n",
    "# Summary of overall accuracy \n",
    "probTest, probTrain = model.predict_prob_int( Xtest = Xtest, Xtrain = Xtrain )\n",
    "tau = optimalTau(probTrain, ytrain)\n",
    "metTest,_ = calc_metrics(custom_prob = probTest.copy(), tau = tau, y = ytest)\n",
    "metTrain ,_= calc_metrics(custom_prob = probTrain.copy(), tau = tau, y = ytrain)\n",
    "metTestSGMM = pd.DataFrame( [metTest], columns = columns)\n",
    "metTrainSGMM = pd.DataFrame( [metTrain], columns = columns)\n",
    "\n",
    "# Cluster summary\n",
    "metTrainSGc, metTestSGc = metrics_cluster(models = logisRegreSGMM, ytrain = ytrain,\n",
    "                                        ytest = ytest, testlabels = labTestSGMM,\n",
    "                                        trainlabels = labTrainSGMM,\n",
    "                                        Xtrain = Xtrain, Xtest = Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMM iteration: 0, error: 0.06747589399893002\n",
      "BMM iteration: 1, error: 0.01429178544334944\n",
      "BMM iteration: 2, error: 0.013568742703090341\n",
      "BMM iteration: 3, error: 0.04029620641844425\n",
      "BMM iteration: 4, error: 0.0814641138102845\n",
      "BMM iteration: 5, error: 0.0787127738827347\n",
      "BMM iteration: 6, error: 0.054827407217991966\n",
      "BMM iteration: 7, error: 0.03228998664053897\n",
      "BMM iteration: 8, error: 0.019589538113114292\n",
      "BMM iteration: 9, error: 0.012353730017538598\n",
      "BMM iteration: 10, error: 0.007860084190610716\n",
      "BMM iteration: 11, error: 0.005323977512962532\n",
      "BMM iteration: 12, error: 0.0041762253519136575\n",
      "BMM iteration: 13, error: 0.003858071805608902\n",
      "BMM iteration: 14, error: 0.00373756806695684\n",
      "BMM iteration: 15, error: 0.0038235782502489464\n",
      "BMM iteration: 16, error: 0.0037810266963984943\n",
      "BMM iteration: 17, error: 0.0037594194234194674\n",
      "BMM iteration: 18, error: 0.0031440676399008623\n",
      "BMM iteration: 19, error: 0.0020995155448616685\n",
      "BMM iteration: 20, error: 0.0015030231203171376\n",
      "BMM iteration: 21, error: 0.0011254413554251633\n",
      "BMM iteration: 22, error: 0.0008758955294286875\n"
     ]
    }
   ],
   "source": [
    "# train SBMM model with Log Regression\n",
    "\n",
    "np.random.seed( seed = 9765  )\n",
    "\n",
    "max_iter = 30\n",
    "max_iter2 = 30\n",
    "n_clusters = 7\n",
    "\n",
    "modelB = SupervisedBMM( max_iter =max_iter, n_clusters = n_clusters, max_iter2 = max_iter2,verbose =0)\n",
    "modelB = modelB.fitB( Xtrain = Xtrain, Xtest = Xtest, ytrain = ytrain)\n",
    "\n",
    "mTrainSBMM = modelB.mTrain\n",
    "logisRegreB = modelB.LogRegr\n",
    "fitPB = modelB.fitParams\n",
    "labTrainSBMM  = fitPB['labTrain']\n",
    "mTestSBMM = modelB.predict_BMMS(Xtest)\n",
    "labTestSBMM = np.argmax( mTestSBMM, axis = 1 )\n",
    "\n",
    "probTestB, probTrainB = modelB.predict_prob_int_B( Xtest = Xtest, Xtrain = Xtrain )\n",
    "tauB = optimalTau(probTrainB, ytrain)\n",
    "metTestB,_ = calc_metrics(custom_prob = probTestB.copy(), tau = tauB, y = ytest)\n",
    "metTrainB ,_= calc_metrics(custom_prob = probTrainB.copy(), tau = tauB, y = ytrain)\n",
    "metTestSBMM = pd.DataFrame( [metTestB], columns = columns)\n",
    "metTrainSBMM = pd.DataFrame( [metTrainB], columns = columns)\n",
    "\n",
    "metTrainSBc, metTestSBc = metrics_cluster(models = logisRegreB, ytrain = ytrain,\n",
    "                                        ytest = ytest, testlabels = labTestSBMM,\n",
    "                                        trainlabels = labTrainSBMM,\n",
    "                                        Xtrain = Xtrain, Xtest = Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall predition accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison acucuracy with other methods\n",
    "trainmet = pd.concat([metTrainNB, metTrainL1,metTrainNN,metTrainRF,metTrainXB,metTrainGB, metTrainKMS,metTrainSGMM,metTrainSBMM],ignore_index=True)\n",
    "testmet = pd.concat([metTestNB, metTestL1,metTestNN,metTestRF,metTestXB,metTestGB, metTestKMS,metTestSGMM,metTestSBMM],ignore_index=True)\n",
    "method = ['Naive Bayes','L1 Log Reg','Neural Network','Random Forest','AdaBoost','GradBoost','KMS + Log Reg', 'SGMM w/ Log Reg', 'SBMM w/ Log Reg']\n",
    "trainmet.insert(8,'method',method)\n",
    "testmet.insert(8,'method',method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall prediction accuracy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>FPR</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1 Log Reg</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradBoost</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KMS + Log Reg</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGMM w/ Log Reg</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SBMM w/ Log Reg</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            method   FPR  specificity  sensitivity  precision  accuracy  \\\n",
       "0      Naive Bayes  0.22         0.78         0.75       0.52      0.77   \n",
       "1       L1 Log Reg  0.13         0.87         0.69       0.63      0.82   \n",
       "2   Neural Network  0.14         0.86         0.71       0.62      0.82   \n",
       "3    Random Forest  0.12         0.88         0.64       0.65      0.82   \n",
       "4         AdaBoost  0.19         0.81         0.71       0.55      0.78   \n",
       "5        GradBoost  0.19         0.81         0.73       0.56      0.79   \n",
       "6    KMS + Log Reg  0.16         0.84         0.71       0.59      0.81   \n",
       "7  SGMM w/ Log Reg  0.13         0.87         0.68       0.62      0.82   \n",
       "8  SBMM w/ Log Reg  0.14         0.86         0.70       0.62      0.82   \n",
       "\n",
       "   balanced accuracy    f1   auc  \n",
       "0               0.76  0.62  0.83  \n",
       "1               0.78  0.66  0.87  \n",
       "2               0.78  0.66  0.88  \n",
       "3               0.76  0.64  0.85  \n",
       "4               0.76  0.62  0.84  \n",
       "5               0.77  0.63  0.85  \n",
       "6               0.78  0.65  0.86  \n",
       "7               0.77  0.65  0.87  \n",
       "8               0.78  0.66  0.87  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( 'Overall prediction accuracy')\n",
    "testmet.iloc[:,8:].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cadre wise prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans + LG\n",
      "     size  high_cost%    f1   auc\n",
      "0  1259.0        0.16  0.52  0.84\n",
      "1  1423.0        0.18  0.59  0.85\n",
      "2  1631.0        0.19  0.56  0.83\n",
      "3   924.0        0.20  0.61  0.87\n",
      "4  1799.0        0.23  0.62  0.85\n",
      "5  1456.0        0.24  0.63  0.85\n",
      "6  1480.0        0.51  0.76  0.82\n",
      "SGMM w/ LG\n",
      "     size  high_cost%    f1   auc\n",
      "0   199.0        0.22  0.55  0.82\n",
      "1  8324.0        0.24  0.65  0.87\n",
      "2   404.0        0.27  0.69  0.89\n",
      "3   526.0        0.29  0.68  0.86\n",
      "4    70.0        0.29  0.47  0.57\n",
      "5   298.0        0.37  0.72  0.89\n",
      "6   151.0        0.37  0.68  0.83\n",
      "SBMM w/ LG\n",
      "     size  high_cost%    f1   auc\n",
      "0   551.0        0.10  0.61  0.91\n",
      "1  4160.0        0.16  0.54  0.84\n",
      "2   954.0        0.18  0.61  0.88\n",
      "3   667.0        0.19  0.54  0.82\n",
      "4  1328.0        0.26  0.68  0.88\n",
      "5   829.0        0.39  0.70  0.82\n",
      "6  1483.0        0.53  0.77  0.83\n"
     ]
    }
   ],
   "source": [
    "print('Kmeans + LG')\n",
    "print(metTestKMc.round(2).sort_values(by ='high_cost%').reset_index().iloc[:,np.r_[2:4,-2,-1]])\n",
    "print('SGMM w/ LG')\n",
    "print(metTestSGc.round(2).sort_values(by ='high_cost%').reset_index().iloc[:,np.r_[2:4,-2,-1]]) #.iloc [[1,0,2,3,4],:]) \n",
    "print('SBMM w/ LG')\n",
    "print(metTestSBc.round(2).sort_values(by ='high_cost%').reset_index().iloc[:,np.r_[2:4,-2,-1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (health3)",
   "language": "python",
   "name": "health3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
